library(epiR) #calculate p values for PRCC

load('runs/XXXXX')
LHS.output <- LHS.binary
LHS.output.sbma <- LHS.binary2
results.output <- get.results(LHS.binary)
parameters<-parameters_binary

# 1. Check monotonicity 
##### scatterplot of the result as a function of each parameter: distribution of values returned by the model 
#     in the parameter space sampled by the hypercube and how sensible are these model responses to 
#     the variation of each parameter.
plotscatter(LHS.output, ylab = 'Model output')

##### Hoeffding's D and Spearman's 
library(xtable)
parametersamples=LHS.output[['data']]
output=LHS.output$res[,,1][,2]
hd=hd.p=c()
spm=spm.p=c()
for (i in 1:ncol(parametersamples)){
  hd[[i]]=hoeffd(x=parametersamples[,i], y=output)$D[1,2]
  hd.p[[i]]=hoeffd(x=parametersamples[,i], y=output)$P[1,2]
  spm[[i]]= cor.test(x=parametersamples[,i], y=output,  method = "spearman")$estimate
  spm.p[[i]]=cor.test(x=parametersamples[,i], y=output,  method = "spearman")$p.value
}
corr.table=data.frame(Parameters=parameters, 
                      HoeffdingD=format(round(hd, 3), nsmall = 3), 
                      HoeffdingD.p=format(round(hd.p, 3), nsmall = 3), 
                      SpearmanRank=format(round(spm, 3), nsmall = 3), 
                      SpearmanRank.p=format(round(spm.p, 3), nsmall = 3))
colnames(corr.table)=c('Parameters',
                       'Hoeffding`s D measure', 'Hoeffding`s D p-value', 
                       'Spearman`s rank correlation measure', 'Spearman`s rank correlation p-value')
xtable(corr.table)

#2. Check agreement between runs to decide if our sample size for adequate 
# Symmetric Blest Measure of Agreement (SBMA) between the PRCC coeffients of two runs with different sample sizes.
(mySbma <- sbma(LHS.output, LHS.output.sbma))
# value of -1 indicates complete disagreement between the runs 
# value of 1 indicated complete agreement  (>0.7 acceptable)
# caveat: if none of the model parameters is monotonically correlated with the output, 
# the agreement between runs may stay as low as 0.2 even for very large hypercubes.

# Visualization of analysis 
##### empirical cumulative distribution function used to illustrate the distribution of the model results
plotecdf(LHS.output, 
         xlab = 'Difference in prevalence of ESBL-producing Enterobacteriaceae carriers/bed/day', 
         ylab= 'Proportion of parameters explored', 
         main='Cumulative distribution curve') #outcome has a high probability in the steepest parts of the graph 

##### partial correlation coefficient measures how strong are the inear associations between the result 
# and each input parameter, after removing the linear effect of the other parameters. 
# (CI generated by bootstrapping)
prcc.wo.pvalues<-LHS.output$prcc[[1]]$PRCC
dat= cbind.data.frame(parametersamples, output)
prcc=cbind.data.frame(prcc.wo.pvalues, pvalues= as.numeric(format(round(epi.prcc(dat = dat, sided.test = 2)$p.value, 5), nsmall = 5)))
prcc<-prcc[order(prcc$original, decreasing = TRUE),]
prcc$pvalues<-ifelse(prcc$pvalues<0.001, "<0.001", format(round(prcc$pvalues, 3), nsmall=3))
prcc$hi_lo<-rep(NA, nrow(prcc))
prcc$hi_lo[which(prcc$`min. c.i.`>0 & prcc$pvalues == "<0.001")]='Above'
prcc$hi_lo[which(prcc$`max. c.i.`<0 & prcc$pvalues == "<0.001")]='Below'
prcc$hi_lo[is.na(prcc$hi_lo)]='None'
rownames.prcc<-factor(as.factor(rownames(prcc)), levels = rownames(prcc))

ggplot(data=prcc, mapping = aes(x = rownames.prcc, y = original)) +
  geom_hline(yintercept=0, color = "azure2")+
  geom_point()+
  geom_errorbar(aes(ymin=`min. c.i.`, ymax=`max. c.i.`, color=factor(hi_lo)), width=0.3)+
  scale_color_manual("hi_lo", breaks=c(1,2,3,4),values=c("#F98866","#80BD9E",'grey'))+
  geom_point(aes(fill=factor(hi_lo)),size=2, shape=21)+
  scale_fill_manual("hi_lo",breaks=c(1,2,3,4),values=c("#F98866", "#80BD9E",'grey'))+
  scale_x_discrete(rownames.prcc)+
  scale_y_continuous(limits = c(-1,1))+
  ylab(expression("Partial Ranking Correlation Coefficients"))+
  geom_text(aes(label=prcc$pvalues, y= prcc$original+ (prcc$`std. error`/1.8)), vjust=-1.5)+
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.background = element_blank())
  
##### pic (partial inclination coefficient) is the sensitivity" of the model response in respect to each parameter
pic(LHS.output, nboot=40) 
#represent the beta terms in y = alpha + beta*x regressions, after removing the linear effect of the other parameters

##### Cobweb
outcome.df<-as.data.frame(cbind(LHS.output$data,results.output)) #dummy matrix with parameter values in columns and outcome in last column
names(outcome.df)<- c(parameters_simple,'outcome') #name the columns of the dummy matrix 
for (i in 1:nrow(outcome.df)) {       #label the rows of parameter values that produced top 5% of the outcomes
  if (outcome.df$outcome[i]<quantile(outcome.df$outcome,probs = 0.95)) { 
    outcome.df$top5[i] <-0 } else {
      outcome.df$top5[i] <-1
    }
}
require(plotrix) #load MASS package
blue<-alpha("lightskyblue1", alpha=0.3)
red<-alpha("red", alpha=0.6)
colors<- c(blue, red) #choose 2 colors - 1 for parameters that produced top 5% of outcomes and one for the rest
outcome.df$top5<- as.factor(outcome.df$top5)
parcoordlabel<-function (x, col = 1, lty = 1,  lblcol="black",...) 
{
  df <- as.data.frame(x)
  pr <- lapply(df, pretty)
  rx <- lapply(pr, range, na.rm = TRUE)
  x <- mapply(function(x,r) {
    (x-r[1])/(r[2]-r[1])
  },
  df, rx)
  matplot(1L:ncol(x), t(x), type = "l", col = col, lty = lty, 
          xlab = "", ylab = "", axes = FALSE,...)
  axis(1, at = 1L:ncol(x), labels = c(colnames(x)), las = 2)
  for (i in 1L:ncol(x)) {
    lines(c(i, i), c(0, 1), col = "grey")
    text(c(i, i), seq(0,1,length.out=length(pr[[i]])), labels = pr[[i]], 
         xpd = NA, col=lblcol, cex=0.5)
  }
  invisible()
}
parcoordlabel(outcome.df[,c(1:length(parameters))], col = colors[outcome.df$top5])

