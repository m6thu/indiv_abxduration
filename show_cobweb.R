library(epiR) #calculate p values for PRCC
library(pse)

output1=get(load('runs/LHSdiff_simple_300_notzero14Aug2019_1204BST.Rdata'))
output2=get(load('runs/LHSdiff_simple_700_notzero12Aug2019_2154GMT.Rdata'))
parameters<-parameters_diff_prevalence_freq

# 1. Check monotonicity 
##### scatterplot - see show_scatterplot
##### Hoeffding's D and Spearman's 
library(xtable)
parametersamples=output1[['data']]
output=output1$res[,3,]
hd=hd.p=c()
spm=spm.p=c()
for (i in 1:ncol(parametersamples)){
  hd[[i]]=hoeffd(x=parametersamples[,i], y=output)$D[1,2]
  hd.p[[i]]=hoeffd(x=parametersamples[,i], y=output)$P[1,2]
  spm[[i]]= cor.test(x=parametersamples[,i], y=output,  method = "spearman")$estimate
  spm.p[[i]]=cor.test(x=parametersamples[,i], y=output,  method = "spearman")$p.value
}
corr.table=data.frame(Parameters=parameters, 
                      HoeffdingD=format(round(hd, 3), nsmall = 3), 
                      HoeffdingD.p=format(round(hd.p, 3), nsmall = 3), 
                      SpearmanRank=format(round(spm, 3), nsmall = 3), 
                      SpearmanRank.p=format(round(spm.p, 3), nsmall = 3))
colnames(corr.table)=c('Parameters',
                       'Hoeffding`s D measure', 'Hoeffding`s D p-value', 
                       'Spearman`s rank correlation measure', 'Spearman`s rank correlation p-value')
xtable(corr.table)

#2. Check agreement between runs to decide if our sample size for adequate 
# Symmetric Best Measure of Agreement (SBMA) between the PRCC coeffients of two runs with different sample sizes.
(mySbma <- sbma(output1, output2))
# value of -1 indicates complete disagreement between the runs 
# value of 1 indicated complete agreement  (>0.7 acceptable)
# caveat: if none of the model parameters is monotonically correlated with the output, 
# the agreement between runs may stay as low as 0.2 even for very large hypercubes.

# Visualization of analysis 
##### partial correlation coefficient measures how strong are the inear associations between the result 
# and each input parameter, after removing the linear effect of the other parameters. 
# (CI generated by bootstrapping)
prcc<-output1$prcc[[3]]$PRCC
x.samples=output1[['data']]
y.output=output1$res[,3,1]
dat= cbind.data.frame(x.samples, y.output)
prcc<-prcc[order(prcc$original, decreasing = TRUE),]
prcc$hi_lo<-rep(NA, nrow(prcc))
prcc$hi_lo[which(prcc$`min. c.i.`>0 & prcc$`max. c.i.`>0) ]='Above'
prcc$hi_lo[which(prcc$`max. c.i.`<0 & prcc$`min. c.i.`<0) ]='Below'
prcc$hi_lo[is.na(prcc$hi_lo)]='None'
prcc$hi_lo=as.factor(prcc$hi_lo)
rownames.prcc<-factor(as.factor(rownames(prcc)), levels = rownames(prcc))
Colors <- setNames(c('#eb5160',"#388697",'grey'), c('Above', 'Below','None'))

ggplot(data=prcc, mapping = aes(x = rownames.prcc, y = original)) +
  geom_hline(yintercept=0, color = "azure2")+
  geom_point()+
  geom_errorbar(aes(ymin=`min. c.i.`, ymax=`max. c.i.`, color=hi_lo), width=0.3)+
  scale_color_manual("hi_lo", breaks=c(1,2,3,4),values=Colors)+
  geom_point(aes(fill=hi_lo),size=2, shape=21)+
  scale_fill_manual("hi_lo",breaks=c(1,2,3,4),values=Colors)+
  scale_x_discrete(rownames.prcc)+
  scale_y_continuous(limits = c(-1,1))+
  labs(y="Partial Ranking Correlation Coefficients",
       x="")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.background = element_blank())
  
##### Cobweb
x.samples<-x.samples[, match(rownames(prcc), names(x.samples))] 
outcome.df<-as.data.frame(cbind(x.samples,y.output)) #dummy matrix with parameter values in columns and outcome in last column
for (i in 1:nrow(outcome.df)) {       #label the rows of parameter values that produced top 5% of the outcomes
  if (outcome.df$y.output[i]<quantile(outcome.df$y.output,probs = 0.85)) { 
    outcome.df$top5[i] <-0 } else {
      outcome.df$top5[i] <-1
    }
}
require(plotrix) #load MASS package
blue<-alpha("lightskyblue", alpha=0.05)
red<-alpha("#E85D75", alpha=0.15)
colors<- c(blue, red) #choose 2 colors - 1 for parameters that produced top 5% of outcomes and one for the rest
outcome.df$top5<- as.factor(outcome.df$top5)
parcoordlabel<-function (x, col = 1, lty = 1,  lblcol="black",...) 
{
  df <- as.data.frame(x)
  pr <- lapply(df, pretty)
  rx <- lapply(pr, range, na.rm = TRUE)
  x <- mapply(function(x,r) {
    (x-r[1])/(r[2]-r[1])
  },
  df, rx)
  matplot(1L:ncol(x), t(x), type = "l", col = col, lty = lty, 
          xlab = "", ylab = "Sampled parameter values", axes = FALSE,...)
  axis(1, at = 1L:ncol(x), labels = c(colnames(x)), las = 2, cex.axis=0.7)
  for (i in 1L:ncol(x)) {
    lines(c(i, i), c(0, 1), col = "grey")
    text (c(i, i), seq(0,1,length.out=length(pr[[i]])), labels = pr[[i]], 
         xpd = NA, col=lblcol, cex=0.5)
  }
  invisible()
}
c=parcoordlabel(outcome.df[,c(1:length(parameters))], col = colors[outcome.df$top5])

##put cobweb and PRCC together 


##### pic (partial inclination coefficient) is the sensitivity" of the model response in respect to each parameter
pic(output1, nboot=40) 
#represent the beta terms in y = alpha + beta*x regressions, after removing the linear effect of the other parameters

